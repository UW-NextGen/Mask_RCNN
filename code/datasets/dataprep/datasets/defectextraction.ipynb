{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "from utils.postProcessing import *#img_ellipse_fitting\n",
    "from utils.imageUtils import cropImage\n",
    "from utils import imageUtils, postProcessing, DefectDetectionDataset, evaluation, visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imagefolder = '/srv/home/whao/NextGen/new_debug/run/run1/datasets/dataprep/datasets/Loop_detection/images/'\n",
    "root = '/srv/home/whao/NextGen/new_debug/run/run1/datasets/dataprep/datasets/Loop_detection'\n",
    "\n",
    "# files = os.listdir('/srv/home/whao/NextGen/new_debug/run/run5/datasets/balloon/train/')    \n",
    "dataset = DefectDetectionDataset(data_dir = root, split = 'test')\n",
    "\n",
    "All_Image_Defects_List = list()\n",
    "for item in range(len(dataset)):\n",
    "    img, bboxes, label = dataset[item]\n",
    "    subimages, bboxes = cropImage(img, bboxes)\n",
    "    current_img_defect_List = list()\n",
    "    for subim, bbox in zip(subimages, bboxes):\n",
    "        defects_Dict = dict()\n",
    "        defects_X_List = list()\n",
    "        defects_Y_List = list()\n",
    "        region1 = flood_fitting(subim)\n",
    "        result = (int(region1['centroid'][0]+bbox[0]), int(region1['centroid'][1]+bbox[1]),\n",
    "                    int(region1['minor_axis_length'] / 2), int(region1['major_axis_length'] / 2),\n",
    "                    -region1['orientation'])\n",
    "        rr,cc = draw.ellipse_perimeter(*result)\n",
    "        # rr is row which is x in pixel\n",
    "        # cc is column which is y in pixel\n",
    "        # (rr,cc) represents one data points and there may be redundent data points\n",
    "        assert len(rr) == len(cc)\n",
    "#         flag = 0\n",
    "        for i in range(len(cc)):\n",
    "            if cc[i] <= 1024 and rr[i] <= 1024:\n",
    "                defects_X_List.append(cc[i])\n",
    "                defects_Y_List.append(rr[i])\n",
    "#             if ((cc[i] > 1024 or rr[i] > 1024) and flag == 0):\n",
    "#                 print(files[item])\n",
    "#                 flag = 1\n",
    "        # add defect's x,y corrdinates into the dictionary\n",
    "        # update dictionary\n",
    "        defects_Dict['X'] = defects_X_List\n",
    "        defects_Dict['Y'] = defects_Y_List\n",
    "        current_img_defect_List.append(defects_Dict)\n",
    "    All_Image_Defects_List.append(current_img_defect_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(All_Image_Defects_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int64Toint32(list):\n",
    "    for item in list:\n",
    "        #print( type(item))\n",
    "        item = int(item)\n",
    "        #print( type(item) )\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"via_region_data.json\",\"w+\") as jsonfile:\n",
    "    with open(\"/srv/home/whao/NextGen/new_debug/run/run1/datasets/dataprep/datasets/Loop_detection/testimages.txt\") as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    each_file = dict()\n",
    "    for i in range(len(content)):\n",
    "        img_i = All_Image_Defects_List[i]\n",
    "        file_size = os.path.getsize(imagefolder + '/'+content[i])\n",
    "        filename_size = content[i] + str(file_size)\n",
    "        each_file[filename_size] = {'fileref':\"\",'size':file_size,'filename':content[i]}\n",
    "        each_file[filename_size].update({'base64_img_data':\"\",'file_attributes':{},'regions':{}})\n",
    "        each_bbox = each_file[filename_size]['regions']\n",
    "        for j in range(len(img_i)):\n",
    "            each_bbox.update({str(j):{'shape_attributes':{},'region_attributes':{}}})\n",
    "            each_bbox[str(j)]['shape_attributes'] = {'name':\"polygon\"}\n",
    "            each_bbox[str(j)]['shape_attributes'].update({'all_points_x':[],'all_points_y':[]})\n",
    "            each_bbox[str(j)]['shape_attributes']['all_points_x'] = np.asarray(img_i[j]['X']).tolist()#int64Toint32(img_i[j]['X'])\n",
    "            each_bbox[str(j)]['shape_attributes']['all_points_y'] = np.asarray(img_i[j]['Y']).tolist()#int64Toint32(img_i[j]['Y'])\n",
    "\n",
    "    json.dump(each_file,jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
